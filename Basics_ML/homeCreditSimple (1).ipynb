{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert app_train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-50038657041f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training data shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mapp_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'app_train' is not defined"
     ]
    }
   ],
   "source": [
    "print('Training data shape: ', app_train.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert app_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing data shape: ', app_test.shape)\n",
    "app_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform both training and testing data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_test = pd.get_dummies(app_test)\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "\n",
    "# Add the target back in\n",
    "app_train['TARGET'] = train_labels\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "\n",
    "# Drop the target from the training data\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns = ['TARGET'])\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "    \n",
    "# Feature names\n",
    "features = list(train.columns)\n",
    "\n",
    "# Copy of the testing data\n",
    "test = app_test.copy()\n",
    "\n",
    "# Median imputation of missing values\n",
    "imputer = Imputer(strategy = 'median')\n",
    "\n",
    "# Scale each feature to 0-1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "imputer.fit(train)\n",
    "\n",
    "# Transform both training and testing data\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(app_test)\n",
    "\n",
    "# Repeat with the scaler\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "print('Training data shape: ', train.shape)\n",
    "print('Testing data shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Make the model with the specified regularization parameter\n",
    "log_reg = LogisticRegression(C = 0.0001)\n",
    "\n",
    "# Train on the training data\n",
    "log_reg.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "# Make sure to select the second column only\n",
    "log_reg_pred = log_reg.predict_proba(test)[:, 1]\n",
    "print(log_reg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Scoring response\n",
      "{'fields': ['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'features', 'rawPrediction', 'probability', 'prediction', 'nodeADP_class', 'nodeADP_classes'], 'values': [[1, 1000, 1, 1, 2, 45, 1, 1, 0, -1, -1, 0, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, [0.00011503968227135422, 0.007709539662191428, 2.0457996460399994, 1.2642367813215571, 3.831132075344397, 4.884034679262907, 0.8842975631736183, 0.8331071821743725, 0.0, -0.8592202333921024, -0.8857977160325888, 0.0, 0.01349864129059024, 0.014002011469540138, 0.01429218174953399, 0.01541872501766167, 0.016386852338615445, 0.016771296626639745, 0.060167662256913945, 0.04251526808113944, 0.0562548029411415, 0.06679033373968925, 0.06361700109215314, 0.05629926051908366], [0.3344156515710008, -0.3344156515710008], [0.5828333834051577, 0.41716661659484233], 0.0, 0.0, [0.0, 1.0]], [1, 1000, 1, 1, 2, 45, 1, 1, 0, -1, -1, 0, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, [0.00011503968227135422, 0.007709539662191428, 2.0457996460399994, 1.2642367813215571, 3.831132075344397, 4.884034679262907, 0.8842975631736183, 0.8331071821743725, 0.0, -0.8592202333921024, -0.8857977160325888, 0.0, 0.01349864129059024, 0.014002011469540138, 0.01429218174953399, 0.01541872501766167, 0.016386852338615445, 0.016771296626639745, 0.060167662256913945, 0.04251526808113944, 0.0562548029411415, 0.06679033373968925, 0.06361700109215314, 0.05629926051908366], [0.3344156515710008, -0.3344156515710008], [0.5828333834051577, 0.41716661659484233], 0.0, 0.0, [0.0, 1.0]]]}\n"
     ]
    }
   ],
   "source": [
    "import urllib3, requests, json\n",
    "\n",
    "# retrieve your wml_service_credentials_username, wml_service_credentials_password, and wml_service_credentials_url from the\n",
    "# Service credentials associated with your IBM Cloud Watson Machine Learning Service instance\n",
    "wml_service_credentials_username = \"9cd73f73-1bc4-4695-9b87-2b0bcebd6b9f\"\n",
    "wml_service_credentials_password = \"935833ca-8838-4d08-8679-1a87e267b12e\"\n",
    "wml_service_credentials_url = \"https://ibm-watson-ml.eu-gb.bluemix.net\"\n",
    "wml_credentials={\n",
    "\"url\": wml_service_credentials_url,\n",
    "\"username\": wml_service_credentials_username,\n",
    "\"password\": wml_service_credentials_password\n",
    "}\n",
    "\n",
    "headers = urllib3.util.make_headers(basic_auth='{username}:{password}'.format(username=wml_credentials['username'], password=wml_credentials['password']))\n",
    "url = '{}/v3/identity/token'.format(wml_credentials['url'])\n",
    "response = requests.get(url, headers=headers)\n",
    "mltoken = json.loads(response.text).get('token')\n",
    "\n",
    "header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\n",
    "array_of_values_to_be_scored=[\n",
    "       1,\n",
    "      1000,\n",
    "      1,\n",
    "      1,\n",
    "      2,\n",
    "      45,\n",
    "      1,\n",
    "      1,\n",
    "      0,\n",
    "      -1,\n",
    "      -1,\n",
    "      0,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000]\n",
    "\n",
    "another_array_of_values_to_be_scored=[ 1,\n",
    "      1000,\n",
    "      1,\n",
    "      1,\n",
    "      2,\n",
    "      45,\n",
    "      1,\n",
    "      1,\n",
    "      0,\n",
    "      -1,\n",
    "      -1,\n",
    "      0,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000,\n",
    "      1000]\n",
    "# NOTE: manually define and pass the array(s) of values to be scored in the next line\n",
    "payload_scoring = {\"fields\": [\"ID\", \"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"AGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\", \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\"], \n",
    "                   \"values\": [array_of_values_to_be_scored, another_array_of_values_to_be_scored]}\n",
    "\n",
    "response_scoring = requests.post('https://ibm-watson-ml.eu-gb.bluemix.net/v3/wml_instances/8eb67f5f-a531-4693-99e8-f3ca7773e5dc/deployments/e5f96e0f-3ec5-4104-9d7a-bf4524eaf19b/online', json=payload_scoring, headers=header)\n",
    "print(\"Scoring response\")\n",
    "print(json.loads(response_scoring.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
